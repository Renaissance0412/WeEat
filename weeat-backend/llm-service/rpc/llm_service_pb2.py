# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: llm_service.proto
# Protobuf Python Version: 5.26.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n\x11llm_service.proto\x12\x04\x63hat"S\n\x0b\x43hatMessage\x12\x0f\n\x07user_id\x18\x01 \x01(\t\x12\x0f\n\x07message\x18\x02 \x01(\t\x12"\n\x07history\x18\x03 \x03(\x0b\x32\x11.chat.ChatMessage"Z\n\x12\x43hatMessageRequest\x12\x0f\n\x07user_id\x18\x01 \x01(\t\x12\x0f\n\x07message\x18\x02 \x01(\t\x12"\n\x07history\x18\x03 \x03(\x0b\x32\x11.chat.ChatMessage"&\n\x13\x43hatMessageResponse\x12\x0f\n\x07message\x18\x01 \x01(\t2\x92\x01\n\nLLMService\x12\x43\n\nStreamChat\x12\x18.chat.ChatMessageRequest\x1a\x19.chat.ChatMessageResponse0\x01\x12?\n\x08SyncChat\x12\x18.chat.ChatMessageRequest\x1a\x19.chat.ChatMessageResponseb\x06proto3'
)

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, "llm_service_pb2", _globals)
if not _descriptor._USE_C_DESCRIPTORS:
    DESCRIPTOR._loaded_options = None
    _globals["_CHATMESSAGE"]._serialized_start = 27
    _globals["_CHATMESSAGE"]._serialized_end = 110
    _globals["_CHATMESSAGEREQUEST"]._serialized_start = 112
    _globals["_CHATMESSAGEREQUEST"]._serialized_end = 202
    _globals["_CHATMESSAGERESPONSE"]._serialized_start = 204
    _globals["_CHATMESSAGERESPONSE"]._serialized_end = 242
    _globals["_LLMSERVICE"]._serialized_start = 245
    _globals["_LLMSERVICE"]._serialized_end = 391
# @@protoc_insertion_point(module_scope)
